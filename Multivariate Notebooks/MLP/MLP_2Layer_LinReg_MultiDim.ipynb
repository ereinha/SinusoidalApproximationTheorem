{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJeOzGiPYJLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import least_squares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujk7-NPTY8tJ"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNzPWDFwCKrr"
      },
      "outputs": [],
      "source": [
        "def activation_prime(x):\n",
        "    return (x > 0).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_JSnc-RoyvD"
      },
      "outputs": [],
      "source": [
        "def glorot_uniform(shape, rng):\n",
        "    fan_in, fan_out = shape[0], shape[1] if len(shape) > 1 else 1\n",
        "    limit = np.sqrt(6.0 / (fan_in + fan_out))\n",
        "    return rng.uniform(-limit, limit, size=shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALveadZdrzvC"
      },
      "outputs": [],
      "source": [
        "def fit_two_layer_mlp_leastsq(x_values, y_values, H, *, activation=relu):\n",
        "    \"\"\"\n",
        "    Fit y = w2 Â· phi(W1 x + b1) + b2  by least-squares.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    x_values : (B, N)  input samples\n",
        "    y_values : (B,)    targets\n",
        "    H        : int     hidden width\n",
        "    activation : callable, element-wise non-linearity (default tanh)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    params = { 'W1': (N,H), 'b1': (H,), 'w2': (H,), 'b2': float }\n",
        "    \"\"\"\n",
        "    B, N = x_values.shape\n",
        "\n",
        "    dim_W1 = N * H\n",
        "    dim_b1 = H\n",
        "    dim_w2 = H\n",
        "    dim_b2 = 1\n",
        "    total_dim = dim_W1 + dim_b1 + dim_w2 + dim_b2\n",
        "\n",
        "    rng = np.random.default_rng(0)\n",
        "\n",
        "    W1 = glorot_uniform((N, H), rng) # fan_in=N, fan_out=H\n",
        "    b1 = np.zeros(H)\n",
        "\n",
        "    w2 = glorot_uniform((H,), rng) # fan_in=H, fan_out=1\n",
        "    b2 = np.zeros(1)\n",
        "\n",
        "    theta0 = np.concatenate([W1.ravel(), b1, w2, b2])\n",
        "\n",
        "    def unpack(theta):\n",
        "        idx = 0\n",
        "        W1 = theta[idx : idx+dim_W1].reshape(N, H); idx += dim_W1\n",
        "        b1 = theta[idx : idx+dim_b1];              idx += dim_b1\n",
        "        w2 = theta[idx : idx+dim_w2];              idx += dim_w2\n",
        "        b2 = float(theta[idx])\n",
        "        return W1, b1, w2, b2\n",
        "\n",
        "    # residuals ---------------------------------------------------------------\n",
        "    def residuals(theta):\n",
        "        W1, b1, w2, b2 = unpack(theta)\n",
        "        H1 = activation(x_values @ W1 + b1)        # (B, H)\n",
        "        y_pred = H1 @ w2 + b2                      # (B,)\n",
        "        return y_pred - y_values\n",
        "\n",
        "    def jac(theta):\n",
        "        W1, b1, w2, b2 = unpack(theta)\n",
        "        Z  = x_values @ W1 + b1          # (B, H)\n",
        "        H1 = activation(Z)               # (B, H)\n",
        "        dphi = activation_prime(Z)       # cos or relu'\n",
        "        # dr/dW1:   shape (B, N*H)\n",
        "        J_W1 = (x_values[:,:,None] * (w2[None,:]*dphi)[:,None,:]).reshape(B, -1)\n",
        "        # dr/db1:   shape (B, H)\n",
        "        J_b1 = (w2[None,:]*dphi)\n",
        "        # dr/dw2:   shape (B, H)\n",
        "        J_w2 = H1\n",
        "        # dr/db2:   shape (B, 1)\n",
        "        J_b2 = np.ones((B,1))\n",
        "        return np.hstack([J_W1, J_b1, J_w2, J_b2])\n",
        "\n",
        "    sol = least_squares(residuals, theta0,\n",
        "                        method='trf', xtol=1e-8,\n",
        "                        ftol=1e-8, jac=jac)\n",
        "\n",
        "    W1_opt, b1_opt, w2_opt, b2_opt = unpack(sol.x)\n",
        "    return {'W1': W1_opt, 'b1': b1_opt, 'w2': w2_opt, 'b2': b2_opt,\n",
        "            'activation': activation}\n",
        "\n",
        "\n",
        "def two_layer_mlp_forward(X, params):\n",
        "    \"\"\"\n",
        "    Evaluate the fitted MLP on a batch X (shape (B,N)).\n",
        "    \"\"\"\n",
        "    W1, b1, w2, b2, act = (params['W1'], params['b1'],\n",
        "                           params['w2'], params['b2'],\n",
        "                           params['activation'])\n",
        "    H1 = act(X @ W1 + b1)            # (B, H)\n",
        "    y_pred = H1 @ w2 + b2            # (B,)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDMBg6qe9oRp"
      },
      "outputs": [],
      "source": [
        "def func1(x, y, a=1.5, b=1.0, c=0.5, d=0.5):\n",
        "    return x**2 + y**2 - a * np.exp(-((x - 1)**2 + y**2) / c) - b * np.exp(-((x + 1)**2 + y**2) / d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6mAQ-pr92cM"
      },
      "outputs": [],
      "source": [
        "def func2(x, y, a=1, b=2):\n",
        "    return (a - x)**2 + b*(y - x**2)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eib6UkArvao",
        "outputId": "f3a0a258-1444-4a2b-eea3-a394c58948ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H=20Error = 0.007638936939987898\n",
            "H=40Error = 0.00429309873826222\n",
            "H=60Error = 0.0023987910850574203\n",
            "H=80Error = 0.0017837244485835674\n",
            "H=100Error = 0.0011524307585153845\n",
            "H=20Error = 0.01929376013357411\n",
            "H=40Error = 0.009508958008109136\n",
            "H=60Error = 0.003915580399585727\n",
            "H=80Error = 0.0056541148636453\n",
            "H=100Error = 0.02988694704414553\n"
          ]
        }
      ],
      "source": [
        "input_dim = 2\n",
        "H = 20\n",
        "\n",
        "val_range = np.linspace(1e-2, 1, 100)\n",
        "\n",
        "xx, yy = np.meshgrid(val_range, val_range)  # both shape (N, N)\n",
        "\n",
        "# Flatten to x_values\n",
        "x_values = np.stack([xx.ravel(), yy.ravel()], axis=1)\n",
        "\n",
        "errors = []\n",
        "settings = []\n",
        "\n",
        "for func in [func1, func2]:\n",
        "    y_values = func(x_values[:,0], x_values[:,1])\n",
        "    for scalefactor in [1,2,3,4,5]:\n",
        "        H_new = H * scalefactor\n",
        "        params = fit_two_layer_mlp_leastsq(x_values, y_values, H_new)\n",
        "\n",
        "        y_fit = two_layer_mlp_forward(x_values, params)\n",
        "        error = np.linalg.norm(y_values - y_fit) / np.linalg.norm(y_values)\n",
        "        print(f'H={H_new}Error = {error}')\n",
        "        errors.append(error)\n",
        "        settings.append((func.__name__, H_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_MRslGm7xDh"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "with open('/content/drive/MyDrive/mlp_2layer_relu_multi_dim_settings.pkl', 'wb') as f:\n",
        "    pkl.dump(settings, f)\n",
        "with open('/content/drive/MyDrive/mlp_2layer_relu_multi_dim_errors.pkl', 'wb') as f:\n",
        "    pkl.dump(errors, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2alL5suDKX5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}